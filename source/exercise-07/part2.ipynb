{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparations\n",
    "import os\n",
    "from PIL import Image\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import glob\n",
    "from itertools import compress\n",
    "\n",
    "import scipy\n",
    "from scipy.ndimage import maximum_filter\n",
    "from scipy.ndimage.interpolation import map_coordinates\n",
    "from scipy.ndimage.filters import convolve1d as conv1\n",
    "from scipy.ndimage.filters import convolve as conv2\n",
    "\n",
    "from skimage.transform import resize, rotate, SimilarityTransform\n",
    "from skimage.io import imread\n",
    "from skimage.measure import ransac\n",
    "\n",
    "from pyflann import *\n",
    "from utils import kdtreequery, matchWords, plotMatches, geometricVerification, getHistogramFromDescriptor, plotRetrievedImages, findNeighbours, plotFrameBoth\n",
    "\n",
    "import time\n",
    "\n",
    "# Select data directory\n",
    "if os.path.isdir('/coursedata'):\n",
    "    course_data_dir = '/coursedata'\n",
    "elif os.path.isdir('../data'):\n",
    "    course_data_dir = '../data'\n",
    "else:\n",
    "    # Specify course_data_dir on your machine\n",
    "    course_data_dir = '/home/jovyan/work/coursedata/'\n",
    "\n",
    "print('The data directory is %s' % course_data_dir)\n",
    "data_dir = os.path.join(course_data_dir, 'exercise-07-data')\n",
    "print('Data stored in %s' % data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description:\n",
    "#    Exercise7 VGG practical notebook (Part2, fast track).\n",
    "#\n",
    "# This software is inspired by original object instance recognition\n",
    "# VGG practical. \n",
    "# Licence; please refer to the file \n",
    "# Licence.txt, included with the software, for details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS-E4850 Computer Vision Exercise Round 7\n",
    "This is a minimal python version of Oxford Visual Geometry Group's Matlab practical on recognition of object instances (see the original webpage <a href= http://www.robots.ox.ac.uk/~vgg/practicals/instance-recognition/index.html#part3>here</a>). By \"minimal\" it is meant that it uses pre-computed SIFT features and some other needed resources. All of them are calculated using the freely available matlab scripts found in the practical's github <a href=https://github.com/vedaldi/practical-object-instance-recognition >repository</a>. The practical is largely based on the vlfeat library (cf. http://www.vlfeat.org/) which unfortunately does not have a Python interface. \n",
    "<br><br>\n",
    "This notebook is <b>the second part (PART II)</b> of the practical on the so-called <em>fast-track</em> and demonstrates the operation of <b>affine co-variant detectors</b>.\n",
    "<br><br>\n",
    "Go through the notebook and answer the questions. You can write your answers to a separate text document and submit that as you are not supposed to implement anything in this exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II: Affine co-variant detectors\n",
    "So far the change in viewpoint between images has been a similarity transformation. Now we consider more severe viewpoint changes - for example where an object is fronto-parallel in one view, and turns away from the camera in the other as in the graffiti wall images below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im1 = imread(data_dir+'/data/graf/img1.png') / 255.\n",
    "im4 = imread(data_dir+'/data/graf/img4.png') / 255.\n",
    "im6 = imread(data_dir+'/data/graf/img6.png') / 255.\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(15,15))\n",
    "ax.imshow(np.hstack((im6, im4, im1)))\n",
    "ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, there is foreshortening (anisotropic scaling) and perspective distortions between the images (as well as in-plane rotation, translation and scaling). A circle in one image cannot cover the same scene area as a circle in the other, but an ellipse can. Affine co-variant detectors are designed to find such regions.\n",
    "\n",
    "In the following we will compare the number of matches using a similarity and affine co-variant detector as the viewpoint becomes progressively more extreme. The detectors are SIFT (for similarity) and SIFT+affine adaptation (for affine), while the descriptor are in both cases SIFT.\n",
    "\n",
    "Task: Examine and run the python code lines below.\n",
    "\n",
    "Note the behaviour in the number of verified matches as the viewpoint becomes more extreme. Observe that the matches also identify the regions of the images that are in common.\n",
    "\n",
    "<b>Question</b>: The transformation between the images induced by the plane is a planar homography. The detections are only affine co-variant (not as general as a planar homography). So how can descriptors computed on these detections possibly match?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## -------------------------------------------------------------------\n",
    "#      Preparations\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "# choose which images to use in the evaluation\n",
    "imgPaths = [data_dir+'/data/graf/img1.png', \\\n",
    "            data_dir+'/data/graf/img2.png', \\\n",
    "            data_dir+'/data/graf/img3.png', \\\n",
    "            data_dir+'/data/graf/img4.png', \\\n",
    "            data_dir+'/data/graf/img5.png', \\\n",
    "            data_dir+'/data/graf/img6.png'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeatures(imid, ftype):\n",
    "    data = np.load(data_dir+'/data_part2/img{}_sift_{}_kps_descrs.npy'.format(imid,ftype), encoding='latin1', allow_pickle=True)\n",
    "    kps = data.item().get('keypoints')\n",
    "    descrs = data.item().get('descriptors')\n",
    "    kps = kps.T\n",
    "    descrs = descrs.T\n",
    "    return kps, descrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_identifier = '1'\n",
    "ii = [i for i, s in enumerate(imgPaths) if file_identifier in s]\n",
    "ii = ii[0]\n",
    "\n",
    "imgPaths2 = [s for i, s in enumerate(imgPaths) if file_identifier  not in s]\n",
    "\n",
    "ftype=['disc', 'ellipse']\n",
    "\n",
    "numInliers = np.zeros((5,2))\n",
    "\n",
    "fig, axes = plt.subplots(nrows=5, ncols=2, figsize=(15,15))\n",
    "ax = axes.ravel(order='F')\n",
    "htype = ['similarity','affinity']\n",
    "for i in range(2):\n",
    "    im1 = imread(imgPaths[ii]) / 255.\n",
    "\n",
    "    kps1, descrs1 = getFeatures(file_identifier, ftype[i])\n",
    "    \n",
    "    for iii, imPath in enumerate(imgPaths2):\n",
    "        im2 = imread(imPath) / 255.\n",
    "        fid = imPath.rstrip(\".png\")\n",
    "        fid = fid.lstrip(data_dir+\"/data/graf/\")\n",
    "        \n",
    "        kps2, descrs2 = getFeatures(fid, ftype[i])\n",
    "\n",
    "        # Perform matching\n",
    "        ind, dist = findNeighbours(descrs1, descrs2, 2)\n",
    "        \n",
    "        # Second nearest neighbour pre-filtering\n",
    "        nnThreshold = 0.80\n",
    "        ratio2 = np.divide(dist[:,0], dist[:,1])\n",
    "        ok = ratio2 <= nnThreshold ** 2\n",
    "        matches_raw = np.vstack((np.nonzero(ok), ind[ok, 0]))\n",
    "        matches_raw = matches_raw.T\n",
    "        \n",
    "        # Geometric verification\n",
    "        inliers_raw, H_raw = geometricVerification(kps1, kps2, matches_raw, 6)\n",
    "        matches_geom = matches_raw[inliers_raw,:]\n",
    "        \n",
    "        # Count the number of inliers\n",
    "        numInliers[iii,i] = matches_geom.shape[0]\n",
    "\n",
    "        # Visualize\n",
    "        ax[i*5+iii].set_title(\"From 1 to {} with {} (matches: {})\".format(iii+2, htype[i], int(matches_geom.shape[0])))\n",
    "        plotFrameBoth(ax[i*5+iii], im1, im2, kps1, kps2, matches_geom, plotMatches=True)\n",
    "        ax[i*5+iii].axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantitative evaluation\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(8,8))\n",
    "x = np.arange(1,6)\n",
    "ax.plot(x, numInliers[:,0], color = 'C1', lineWidth=2, linestyle='--', marker='o')\n",
    "ax.plot(x, numInliers[:,1], color = 'C2', lineWidth=2, linestyle='--', marker='o')\n",
    "plt.title(\"Part II: Affine co-variant detectors - quantitative comparison\")\n",
    "plt.xlabel('image pair')\n",
    "plt.ylabel('number of verified feature matches')\n",
    "plt.legend(('similarity co-variant', 'affine co-variant'))\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
