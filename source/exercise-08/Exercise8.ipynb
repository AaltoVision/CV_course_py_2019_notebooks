{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description:\n",
    "#   Exercise9 python demo.\n",
    "#\n",
    "# Copyright (C) 2018 Santiago Cortes, Juha Ylioinas, Tapio Honka\n",
    "#\n",
    "# This software is distributed under the GNU General Public \n",
    "# Licence (version 2 or later); please refer to the file \n",
    "# Licence.txt, included with the software, for details.\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from goodFeaturesToTrackFromFace import detect as ShiTomasi_detect\n",
    "from skimage.transform import SimilarityTransform\n",
    "from skimage.measure import ransac\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "if os.path.isdir('/coursedata'):\n",
    "    course_data_dir = '/coursedata'\n",
    "elif os.path.isdir('../data'):\n",
    "    course_data_dir = '../data'\n",
    "else:\n",
    "    # Specify course_data_dir on your machine\n",
    "    course_data_dir = '/home/jovyan/work/coursedata/'\n",
    "\n",
    "print('The data directory is %s' % course_data_dir)\n",
    "data_dir = os.path.join(course_data_dir, 'exercise-08-data')\n",
    "print('Data stored in %s' % data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# This demo illustrates an application of Lucas-Kanade optical flow\n",
    "#\n",
    "# Steps:\n",
    "#   1) detect face region using pretrained haarcascade classifiers\n",
    "#   2) detect good features to track from face region using Shi-Tomasi corner detector\n",
    "#   3) track the points using the Lucas-Kanade optical flow\n",
    "#\n",
    "\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "\n",
    "# setup a video capture from file (webcam also possible, for that see OpenCV docs)\n",
    "# Choose the source video\n",
    "cap = cv2.VideoCapture(data_dir+'/santi.avi')\n",
    "#cap = cv2.VideoCapture(data_dir+'/obama.avi')\n",
    "\n",
    "# read the first frame from the video file and convert to grayscale\n",
    "ret, frame = cap.read() \n",
    "old_frame = frame.copy()\n",
    "gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "# display the first frame to make sure reading worked\n",
    "plt.imshow(gray, cmap='gray')\n",
    "\n",
    "# detect points to track, take a look at goodFeaturesToTrackFromFace.py\n",
    "bboxPoints, points = ShiTomasi_detect(gray, data_dir)\n",
    "\n",
    "# create a mask image for drawing the trails of the tracked points\n",
    "mask = np.zeros_like(old_frame)\n",
    "\n",
    "# display the video and track the points\n",
    "oldPoints = points\n",
    "trackingAlive = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "frames = []\n",
    "while cap.isOpened():\n",
    "\n",
    "    # get the next frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # esc breaks the loop, also wait 30ms between every frame\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "    # convert to grayscale\n",
    "    gray_new = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # params for Lucas-Kanade optical flow\n",
    "    winSize = 31#9\n",
    "    maxLevel = 4#1\n",
    "    maxCount = 4#2\n",
    "\n",
    "    if trackingAlive == True:\n",
    "        # track the points (note that some points may be lost)\n",
    "        points, isFound, err = cv2.calcOpticalFlowPyrLK(gray, gray_new, \n",
    "                                            oldPoints, None, winSize = (winSize, winSize), maxLevel = maxLevel, \n",
    "                                            criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, maxCount, 0.03))\n",
    "\n",
    "        visiblePoints = points[isFound==1]\n",
    "        oldInliers = oldPoints[isFound==1]\n",
    "\n",
    "        # need at least two points (otherwise tracks are lost)\n",
    "        if visiblePoints.shape[0] >= 2:\n",
    "\n",
    "            # estimate the geometric transformation between the old points and \n",
    "            # the new points and eliminate outliers\n",
    "            tform, inliers = ransac((oldInliers, visiblePoints), SimilarityTransform, min_samples=2,\n",
    "                               residual_threshold=2, max_trials=200)\n",
    "\n",
    "            H1to2p = tform.params\n",
    "            visiblePoints = visiblePoints[inliers, :]\n",
    "            oldInliers = oldInliers[inliers, :]\n",
    "\n",
    "            # apply the transformation to the bounding box points\n",
    "            bboxPoints_homog = np.hstack((bboxPoints, np.ones((bboxPoints.shape[0], 1))))\n",
    "            bboxPoints_new = np.dot(H1to2p, bboxPoints_homog.T)\n",
    "            bboxPoints_new = bboxPoints_new[:2,:] / bboxPoints_new[2,:]\n",
    "            bboxPoints_new = bboxPoints_new.T\n",
    "            bboxPoints = bboxPoints_new\n",
    "\n",
    "            bboxPoints_new = bboxPoints_new.astype(np.int)\n",
    "            bboxPoints_new = bboxPoints_new.reshape((-1, 1, 2))\n",
    "\n",
    "            # insert a bounding box around the object being tracked\n",
    "            cv2.polylines(frame, [bboxPoints_new], True, (0, 255, 255), 3)\n",
    "\n",
    "            # display tracked points\n",
    "            for i, (new, old) in enumerate(zip(visiblePoints, oldInliers)):\n",
    "                a, b = new.ravel()\n",
    "                c, d = old.ravel()\n",
    "                mask = cv2.line(mask, (a, b),(c, d), (255,255,255), 2)\n",
    "                frame = cv2.circle(frame, (a, b), 2, (255, 255, 255), -1)\n",
    "\n",
    "            # visualize tracks\n",
    "            mask = 0.7 * mask\n",
    "            oldPoints = visiblePoints.reshape(-1, 1, 2)\n",
    "            gray = gray_new.copy()\n",
    "\n",
    "            # display the number of tracked points\n",
    "            cv2.putText(frame, 'Number of tracked points: ' + str(visiblePoints.shape[0]), (20,30), 0, 1.1, (255,255,255))\n",
    "            frame = cv2.add(frame, np.uint8(mask))\n",
    "            frame = plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB), animated=True)\n",
    "            frames.append([frame])\n",
    "        else:\n",
    "            trackingAlive = False\n",
    "            \n",
    "# close everything\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ani = animation.ArtistAnimation(fig, frames, interval=50, blit=True, repeat_delay=2000)\n",
    "display(HTML(ani.to_html5_video()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
