{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML('''<script>\n",
    "code_show=true;\n",
    "function code_toggle() {\n",
    "if (code_show){\n",
    "$('div.input').hide();\n",
    "} else {\n",
    "$('div.input').show();\n",
    "}\n",
    "code_show = !code_show\n",
    "}\n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description:\n",
    "#   Exercise11 notebook.\n",
    "#\n",
    "# Copyright (C) 2018 Tapio Honka, Santiago Cortes, Juha Ylioinas\n",
    "#\n",
    "# This software is distributed under the GNU General Public \n",
    "# Licence (version 2 or later); please refer to the file \n",
    "# Licence.txt, included with the software, for details.\n",
    "\n",
    "# Preparations\n",
    "import os\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import vgg_KR_from_P\n",
    "\n",
    "# Select data directory\n",
    "if os.path.isdir('/coursedata'):\n",
    "    course_data_dir = '/coursedata'\n",
    "elif os.path.isdir('../data'):\n",
    "    course_data_dir = '../data'\n",
    "else:\n",
    "    # Specify course_data_dir on your machine\n",
    "    course_data_dir = '/home/jovyan/work/coursedata/'\n",
    "\n",
    "print('The data directory is %s' % course_data_dir)\n",
    "data_dir = os.path.join(course_data_dir, 'exercise-11-data')\n",
    "print('Data stored in %s' % data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS-E4850 Computer Vision Exercise Round 11\n",
    "\n",
    "The problems should be solved before the exercise session and solutions returned via MyCourses. Upload to MyCourses both: this Jupyter Notebook (.ipynb) file containing your solutions to the programming tasks and the exported pdf version of this Notebook file.\n",
    "Note that (1) you are not supposed to change anything in the utils.py and (2) you should be sure that everything that that you need to implement should work with the pictures specified by the assignments of this exercise round."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 - Camera calibration\n",
    "\n",
    "In this exercise you will need to implement the direct linear transform (DLT) method for camera calibration. The algorithm is described on slide 22 of Lecture 10. It is also presented in the book by Hartley \\& Zisserman (Section 7.1 in the second edition). \n",
    "\n",
    "The calibration object is a bookshelf whose dimensions are known. That is, width of a shelf is 758 mm, depth is 295 mm, and height between shelves is 360 mm.\n",
    "\n",
    "Proceed as follows:\n",
    "\n",
    "a) Check the cells below and try to run them.<br>\n",
    "b) The corners of the bookshelf are already manually localized from the given two images and visualized by the script. See the comments in the source code.<br>\n",
    "c) Implement the missing function <b>camcalibDLT</b>.<br>\n",
    "d) Calibrate both cameras and check the results visually by uncommenting the relevant lines from the example code.<br>\n",
    "e) Report the estimated intrinsic camera calibration matrices for both cameras (i.e.variables $K_{1}, K_{2}$). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im1 = imread(data_dir+'/im1.jpg')\n",
    "im2 = imread(data_dir+'/im2.jpg')\n",
    "\n",
    "# The given image coordinates were originally localized manually \n",
    "# using Matlab's ginput\n",
    "# x1,y1 = ginput(8)\n",
    "\n",
    "# Im1 annotations\n",
    "x1 = 1.0e+03 * np.array([0.7435, 3.3315, 0.8275, 3.2835, \n",
    "                      0.5475, 3.9875, 0.6715, 3.8835])\n",
    "    \n",
    "y1 = 1.0e+03 * np.array([0.4455, 0.4335, 1.7215, 1.5615, \n",
    "                      0.3895, 0.3895, 2.1415, 1.8735])\n",
    "\n",
    "# Im2 annotations\n",
    "x2 = 1.0e+03 * np.array([0.5835, 3.2515, 0.6515, 3.1995, \n",
    "                    0.1275, 3.7475, 0.2475, 3.6635])\n",
    "    \n",
    "y2 = 1.0e+03 * np.array([0.4135, 0.4015, 1.6655, 1.5975, \n",
    "                     0.3215, 0.3135, 2.0295, 1.9335])\n",
    "                      \n",
    "# Image coordinates of points as rows of matrix 'abcdefgh'\n",
    "abcdefgh = np.vstack((x1, y1)).T\n",
    "\n",
    "# World coordinates of the points\n",
    "ABCDEFGH_w = np.array([[758, 0, -295], [0, 0, -295], [758, 360, -295],\n",
    "                    [0, 360, -295], [758, 0, 0], [0, 0, 0], [758, 360, 0],\n",
    "                    [0, 360, 0]])\n",
    "\n",
    "labels = ['a','b','c','d','e','f','g','h']\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15,15))\n",
    "ax = axes.ravel()\n",
    "ax[0].imshow(im1)\n",
    "ax[0].plot(x1, y1, 'c+', markersize=10)\n",
    "for i in range(len(x1)):    \n",
    "    ax[0].annotate(labels[i], (x1[i], y1[i]), color='c', fontsize=20)\n",
    "ax[0].set_title(\"Input Image 1\")\n",
    "\n",
    "ax[1].imshow(im2)\n",
    "ax[1].plot(x2, y2, 'c+', markersize=10)\n",
    "for i in range(len(x2)):    \n",
    "    ax[1].annotate(labels[i], (x2[i], y2[i]), color='c', fontsize=20)\n",
    "ax[1].set_title(\"Input Image 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def camcalibDLT(Xworld, Xim):\n",
    "    ##-your-code-starts-here-##\n",
    "\n",
    "    \n",
    "    \n",
    "    ##-your-code-starts-here-##\n",
    "    return P\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## the task is to implement the missing function camcalibDLT.\n",
    "# The algorithm is summarised on slide 22 of Lecture 10.\n",
    "# The function takes the homogeneous coordinates of the points as input.\n",
    "\n",
    "## Calibration of camera 1\n",
    "\n",
    "# Uncomment the code lines below once you have implemented the camcalibDLT function.\n",
    "#P1 = camcalibDLT(np.hstack((ABCDEFGH_w, np.ones((8,1)))), \n",
    "#                 np.hstack((abcdefgh, np.ones((8,1)))))\n",
    "\n",
    "# Check the results by projecting the world points with the estimated P.\n",
    "# The projected points should overlap with manually localized points\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15,15))\n",
    "ax = axes.ravel()\n",
    "ax[0].imshow(im1)\n",
    "\n",
    "# plot manually localized\n",
    "ax[0].plot(x1, y1, 'c+', markersize=10)\n",
    "for i in range(len(x1)):    \n",
    "    ax[0].annotate(labels[i], (x1[i], y1[i]), color='c', fontsize=20)\n",
    "ax[0].set_title(\"Input Image 1\")\n",
    "\n",
    "# plot projected\n",
    "#pproj1 = np.dot(P1, np.hstack((ABCDEFGH_w, np.ones((8,1)))).T)\n",
    "#for i in range(8):\n",
    "#    ax[0].plot(pproj1[0,i] / pproj1[2,i], pproj1[1,i] / pproj1[2,i], 'rx', markersize=12)\n",
    "\n",
    "    \n",
    "## Calibration of camera 2    \n",
    "\n",
    "# Uncomment the code lines below once you have implemented the camcalibDLT function.\n",
    "#P2 = camcalibDLT(np.hstack((ABCDEFGH_w, np.ones((8,1)))), \n",
    "#                 np.vstack((x2,y2, np.ones(8))).T)\n",
    "\n",
    "# Check the results by projecting the world points with the estimated P.\n",
    "# The projected points should overlap with manually localized points\n",
    "ax[1].imshow(im2)\n",
    "ax[1].plot(x2, y2, 'c+', markersize=10)\n",
    "\n",
    "# plot manually localized\n",
    "for i in range(len(x2)):    \n",
    "    ax[1].annotate(labels[i], (x2[i], y2[i]), color='c', fontsize=20)\n",
    "ax[1].set_title(\"Input Image 2\")\n",
    "\n",
    "# plot projected\n",
    "#pproj2 = np.dot(P2, np.hstack((ABCDEFGH_w, np.ones((8,1)))).T)\n",
    "#for i in range(8):\n",
    "#    ax[1].plot(pproj2[0,i] / pproj2[2,i], pproj2[1,i] / pproj2[2,i], 'rx', markersize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Intrinsic and extrinsic camera parameters K,R,t can be extracted from P\n",
    "## the following functions are from http://www.robots.ox.ac.uk/~vgg/hzbook/code/\n",
    "\n",
    "K1, R1, t1 = vgg_KR_from_P(P1)\n",
    "K2, R2, t2 = vgg_KR_from_P(P2)\n",
    "\n",
    "## Finally, save P1 and P2 for part 2 of this exercise\n",
    "np.save('P1.npy', P1)\n",
    "np.save('P2.npy', P2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 - Triangulation\n",
    "In this exercise you will need to implement the linear triangulation method described on slides 31 and 32 of Lecture 10.  (The method is also presented in the book by Hartley \\& Zisserman.) You must again find a least-squares solution to a system of linear equations. In a similar manner as in exercise problem 1, it can be computed by solving the eigenvectors and eigenvalues of a real symmetric matrix (see numpy's built-in function np.linalg.eig).\n",
    "\n",
    "As illustrated by the example script, the points that will be triangulated are the corner points of the picture on the cover of the course book. As a result of the triangulation we will get the coordinates of these corner points in the world coordinate frame. By computing the distances between the points, we can measure the width and height of the picture in millimeters.\n",
    "\n",
    "Proceed as follows:\n",
    "\n",
    "a) Check the cells below and try to run them. <br>\n",
    "b) The corners of the picture on the book cover are already manually localized from the given two images and visualized by the script. See the comments in the source code. <br>\n",
    "c) Implement the missing function <b>trianglin</b>. <br>\n",
    "d) Triangulate the three given point correspondences. Here you will need also the estimated camera projection matrices ($P_{1}, P_{2}$) from exercise problem 1. You can use the same projection matrices here because the two images are the same as in the calibration problem.<br>\n",
    "e) Report the estimated width and height of the picture by computing the distances between triangulated points.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of three point correspondences in both images\n",
    "im1 = imread(data_dir+'/im1.jpg')\n",
    "im2 = imread(data_dir+'/im2.jpg')\n",
    "\n",
    "# Points L, M, N in image 1\n",
    "lmn1 = 1.0e+03 * np.array([[1.3715, 1.0775], \n",
    "                        [1.8675, 1.0575], \n",
    "                        [1.3835, 1.4415]])\n",
    "\n",
    "# Points L, M, N in image 2\n",
    "lmn2 = 1.0e+03 * np.array([[1.1555, 1.0335],\n",
    "                        [1.6595, 1.0255],\n",
    "                        [1.1755, 1.3975]])\n",
    "                   \n",
    "pointlabels=['l','m','n']\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15,15))\n",
    "ax = axes.ravel()\n",
    "ax[0].imshow(im1)\n",
    "ax[0].plot(lmn1[:,0], lmn1[:,1], 'c+', markersize=10)\n",
    "for i in range(len(lmn1)):    \n",
    "    ax[0].annotate(pointlabels[i], (lmn1[i,0], lmn1[i,1]), color='c', fontsize=20)\n",
    "ax[0].set_title(\"Input Image 1\")\n",
    "\n",
    "ax[1].imshow(im2)\n",
    "ax[1].plot(lmn2[:,0], lmn2[:,1], 'c+', markersize=10)\n",
    "for i in range(len(lmn2)):    \n",
    "    ax[1].annotate(pointlabels[i], (lmn2[i,0], lmn2[i,1]), color='c', fontsize=20)\n",
    "ax[1].set_title(\"Input Image 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trianglin(P1, P2, x1, x2):\n",
    "    ##-your-code-starts-here-##\n",
    "\n",
    "    ##-your-code-ends-here-##\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## the task is to implement the missing function trianglin.\n",
    "# The algorithm is described on slides 31 and 32 of Lecture 10.\n",
    "# Output should be the homogeneous coordinates of the triangulated point.\n",
    "\n",
    "# Load the projection matrices from the first part\n",
    "P1 = np.load('P1.npy', encoding='latin1')\n",
    "P2 = np.load('P2.npy', encoding='latin1')\n",
    "\n",
    "# Uncomment the lines below once you have implemented the trianglin function.\n",
    "#L = trianglin(P1, P2, np.hstack((lmn1[0,:].T, [1])), \n",
    "#                      np.hstack((lmn2[0,:].T, [1])))\n",
    "#M = trianglin(P1, P2, np.hstack((lmn1[1,:].T, [1])), \n",
    "#                      np.hstack((lmn2[1,:].T, [1])))\n",
    "#N = trianglin(P1, P2, np.hstack((lmn1[2,:].T, [1])), \n",
    "#                      np.hstack((lmn2[2,:].T, [1])))\n",
    "                      \n",
    "# We can then compute the width and height of the picture on the book\n",
    "#picture_w_mm = np.linalg.norm(L[0:3] / L[3] - M[0:3] / M[3])\n",
    "#picture_h_mm = np.linalg.norm(L[0:3] / L[3] - N[0:3] / N[3])\n",
    "#print(\"Picture width: %.2f mm\" % picture_w_mm.item())\n",
    "#print(\"Picture height: %.2f mm\" % picture_h_mm.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
